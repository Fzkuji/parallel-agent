# Question Grouping Impact Experiment - SFT-LoRA Sequential
# Model: meta-llama/Meta-Llama-3-8B-Instruct + LoRA (1000 samples, 1 epoch, sequential format)
# Dataset: cmb - 420 questions from 84 contexts (5 questions each)
# Strategy: Sequential (multi-turn) with SFT-LoRA

## Results - Accuracy

GroupSize  |   Sequential |  NumGroups
--------------------------------------
1          |        0.583 |        420
2          |        0.574 |        210
3          |        0.569 |        140
4          |        0.560 |        105
5          |        0.550 |         84


## Token Statistics (Total)

GroupSize  |   Sequential (Prompt Tokens - Deduplicated)
-------------------------
1          |      106,433
2          |       74,391
3          |       63,647
4          |       58,082
5          |       54,844

## Token Statistics (API)

GroupSize  |   Sequential (Prompt Tokens - API)
-------------------------
1          |      106,433
2          |      129,620
3          |      151,631
4          |      175,223
5          |      196,330

## Generated Tokens (Total)

GroupSize  |   Sequential
-------------------------
1          |        3,096
2          |        3,116
3          |        3,122
4          |        3,114
5          |        3,119

## GPU Latency (seconds)

GroupSize  |   Sequential
-------------------------
1          |        65.79
2          |        72.23
3          |        71.66
4          |        75.31
5          |        77.21

## Wall Time (seconds)

GroupSize  |   Sequential
-------------------------
1          |        31.88
2          |        33.24
3          |        34.42
4          |        36.02
5          |        35.95

## Avg Prompt Tokens per Question (Deduplicated)

GroupSize  |   Sequential
-------------------------
1          |        253.4
2          |        177.1
3          |        151.5
4          |        138.3
5          |        130.6

## Avg Prompt Tokens per Question (API)

GroupSize  |   Sequential
-------------------------
1          |        253.4
2          |        308.6
3          |        361.0
4          |        417.2
5          |        467.5

## Avg Generated Tokens per Question

GroupSize  |   Sequential
-------------------------
1          |          7.4
2          |          7.4
3          |          7.4
4          |          7.4
5          |          7.4

## Avg Latency per Question (seconds)

GroupSize  |   Sequential
-------------------------
1          |       0.1566
2          |       0.1720
3          |       0.1706
4          |       0.1793
5          |       0.1838

## API Cost (USD, $0.10/M input + $0.20/M output)

GroupSize  |   Sequential
-------------------------
1          |       11.262
2          |       13.585
3          |       15.788
4          |       18.145
5          |       20.257

## Performance Comparison with 0-shot Sequential

Strategy                     | Acc (G=1) | Acc (G=5) | Improvement
-----------------------------|-----------|-----------|------------
0-shot Sequential            |   54.0%   |   53.3%   |    --
SFT-LoRA Sequential (1KÃ—1ep) |   58.3%   |   55.0%   |  +4.3% / +1.7%

Note: CMB Batch SFT (63.0%) outperforms Sequential SFT (58.3%).
